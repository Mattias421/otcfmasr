# #################################
# Basic training parameters for enhancement.
#
# Authors:
#  * Szu-Wei Fu 2020
#  * Chien-Feng Liao 2020
#  * Peter Plantinga 2020, 2021
# #################################

data_folder: ./data
xp_name: baseline_default
output_folder: !ref ./results/<xp_name>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt


# Path where data manifest files will be stored
# The data manifest files are created by the data preparation script.
train_annotation: !ref <save_folder>/train.json
valid_annotation: !ref <save_folder>/valid.json
test_annotation: !ref <save_folder>/test.json
skip_prep: False

normalized_transcripts: true

# whisper settings
whisper_hub: openai/whisper-tiny
freeze_encoder: true
whisper_folder: !ref ./pretrained/<whisper_hub>
sampling_rate: 16_000

whisper: !new:speechbrain.lobes.models.huggingface_transformers.whisper.Whisper
    source: !ref <whisper_hub>
    freeze_encoder: !ref <freeze_encoder>
    save_path: !ref <whisper_folder>
    language: "english"
    task: "transcribe"
    sampling_rate: !ref <sampling_rate>

modules:
    whisper: !ref <whisper>

# Decoding parameters
min_decode_ratio: 0.0
max_decode_ratio: 1.0
test_beam_size: 8

valid_search: !new:speechbrain.decoders.seq2seq.S2SWhisperGreedySearcher
    model: !ref <whisper>
    min_decode_ratio: !ref <min_decode_ratio>
    max_decode_ratio: !ref <max_decode_ratio>

test_search: !new:speechbrain.decoders.seq2seq.S2SWhisperBeamSearcher
    module: [!ref <whisper>]
    min_decode_ratio: !ref <min_decode_ratio>
    max_decode_ratio: !ref <max_decode_ratio>
    beam_size: !ref <test_beam_size>

# Training Parameters
batch_size: 64
num_workers: 4
dataloader_options:
    batch_size: !ref <batch_size>
    num_workers: !ref <num_workers>
split: test
